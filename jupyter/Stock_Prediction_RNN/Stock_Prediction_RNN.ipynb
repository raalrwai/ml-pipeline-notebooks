{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6Hdv42X2TK9l"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eT3Ri8_cTaEn",
    "outputId": "02cebd39-117f-47c5-fda9-52d2f0e94a6f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "akOCsxgLTlWZ"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'trainset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m \u001b[38;5;66;03m# data processing, CSV file I/O (e.g. pd.read_csv)\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m dataset_train = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrainset.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Rami Alrwais\\Desktop\\training\\jupyter\\env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Rami Alrwais\\Desktop\\training\\jupyter\\env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Rami Alrwais\\Desktop\\training\\jupyter\\env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Rami Alrwais\\Desktop\\training\\jupyter\\env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Rami Alrwais\\Desktop\\training\\jupyter\\env\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'trainset.csv'"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "dataset_train = pd.read_csv('trainset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "lV-DnjyCTw6Q",
    "outputId": "b520847d-c160-4c69-b141-782fe7666c83"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>357.385559</td>\n",
       "      <td>361.151062</td>\n",
       "      <td>355.959839</td>\n",
       "      <td>359.288177</td>\n",
       "      <td>359.288177</td>\n",
       "      <td>5115500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>360.122742</td>\n",
       "      <td>363.600128</td>\n",
       "      <td>358.031342</td>\n",
       "      <td>359.496826</td>\n",
       "      <td>359.496826</td>\n",
       "      <td>4666500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>362.313507</td>\n",
       "      <td>368.339294</td>\n",
       "      <td>361.488861</td>\n",
       "      <td>366.600616</td>\n",
       "      <td>366.600616</td>\n",
       "      <td>5562800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>365.348755</td>\n",
       "      <td>367.301056</td>\n",
       "      <td>362.929504</td>\n",
       "      <td>365.001007</td>\n",
       "      <td>365.001007</td>\n",
       "      <td>3332900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>365.393463</td>\n",
       "      <td>365.771027</td>\n",
       "      <td>359.874359</td>\n",
       "      <td>364.280701</td>\n",
       "      <td>364.280701</td>\n",
       "      <td>3373900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>2017-12-22</td>\n",
       "      <td>1061.109985</td>\n",
       "      <td>1064.199951</td>\n",
       "      <td>1059.439941</td>\n",
       "      <td>1060.119995</td>\n",
       "      <td>1060.119995</td>\n",
       "      <td>755100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>2017-12-26</td>\n",
       "      <td>1058.069946</td>\n",
       "      <td>1060.119995</td>\n",
       "      <td>1050.199951</td>\n",
       "      <td>1056.739990</td>\n",
       "      <td>1056.739990</td>\n",
       "      <td>760600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>2017-12-27</td>\n",
       "      <td>1057.390015</td>\n",
       "      <td>1058.369995</td>\n",
       "      <td>1048.050049</td>\n",
       "      <td>1049.369995</td>\n",
       "      <td>1049.369995</td>\n",
       "      <td>1271900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>2017-12-28</td>\n",
       "      <td>1051.599976</td>\n",
       "      <td>1054.750000</td>\n",
       "      <td>1044.770020</td>\n",
       "      <td>1048.140015</td>\n",
       "      <td>1048.140015</td>\n",
       "      <td>837100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>2017-12-29</td>\n",
       "      <td>1046.719971</td>\n",
       "      <td>1049.699951</td>\n",
       "      <td>1044.900024</td>\n",
       "      <td>1046.400024</td>\n",
       "      <td>1046.400024</td>\n",
       "      <td>887500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1259 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date         Open         High          Low        Close  \\\n",
       "0     2013-01-02   357.385559   361.151062   355.959839   359.288177   \n",
       "1     2013-01-03   360.122742   363.600128   358.031342   359.496826   \n",
       "2     2013-01-04   362.313507   368.339294   361.488861   366.600616   \n",
       "3     2013-01-07   365.348755   367.301056   362.929504   365.001007   \n",
       "4     2013-01-08   365.393463   365.771027   359.874359   364.280701   \n",
       "...          ...          ...          ...          ...          ...   \n",
       "1254  2017-12-22  1061.109985  1064.199951  1059.439941  1060.119995   \n",
       "1255  2017-12-26  1058.069946  1060.119995  1050.199951  1056.739990   \n",
       "1256  2017-12-27  1057.390015  1058.369995  1048.050049  1049.369995   \n",
       "1257  2017-12-28  1051.599976  1054.750000  1044.770020  1048.140015   \n",
       "1258  2017-12-29  1046.719971  1049.699951  1044.900024  1046.400024   \n",
       "\n",
       "        Adj Close   Volume  \n",
       "0      359.288177  5115500  \n",
       "1      359.496826  4666500  \n",
       "2      366.600616  5562800  \n",
       "3      365.001007  3332900  \n",
       "4      364.280701  3373900  \n",
       "...           ...      ...  \n",
       "1254  1060.119995   755100  \n",
       "1255  1056.739990   760600  \n",
       "1256  1049.369995  1271900  \n",
       "1257  1048.140015   837100  \n",
       "1258  1046.400024   887500  \n",
       "\n",
       "[1259 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "dataset_train = pd.read_csv('trainset.csv')\n",
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "emcZ4jSYT1kY"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "dataset_train = pd.read_csv('trainset.csv')\n",
    "dataset_train\n",
    "trainset = dataset_train.iloc[:,1:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6craYXaST5CD",
    "outputId": "094fa9b8-481c-4c5e-9d87-defae419a63e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 357.385559],\n",
       "       [ 360.122742],\n",
       "       [ 362.313507],\n",
       "       ...,\n",
       "       [1057.390015],\n",
       "       [1051.599976],\n",
       "       [1046.719971]], shape=(1259, 1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "dataset_train = pd.read_csv('trainset.csv')\n",
    "dataset_train\n",
    "trainset = dataset_train.iloc[:,1:2].values\n",
    "trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZQjfLTkRT76N"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "dataset_train = pd.read_csv('trainset.csv')\n",
    "dataset_train\n",
    "trainset = dataset_train.iloc[:,1:2].values\n",
    "trainset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0,1))\n",
    "training_scaled = sc.fit_transform(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "icyw9-A0UALd",
    "outputId": "581e7c81-0eb7-4bfe-c3b3-92ccd151d55e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01011148],\n",
       "       [0.01388614],\n",
       "       [0.01690727],\n",
       "       ...,\n",
       "       [0.97543954],\n",
       "       [0.9674549 ],\n",
       "       [0.96072522]], shape=(1259, 1))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "dataset_train = pd.read_csv('trainset.csv')\n",
    "dataset_train\n",
    "trainset = dataset_train.iloc[:,1:2].values\n",
    "trainset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0,1))\n",
    "training_scaled = sc.fit_transform(trainset)\n",
    "training_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HMlcMDBuUDIl"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "dataset_train = pd.read_csv('trainset.csv')\n",
    "dataset_train\n",
    "trainset = dataset_train.iloc[:,1:2].values\n",
    "trainset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0,1))\n",
    "training_scaled = sc.fit_transform(trainset)\n",
    "training_scaled\n",
    "x_train = []\n",
    "y_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3t7KnBcNUGm7"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "dataset_train = pd.read_csv('trainset.csv')\n",
    "dataset_train\n",
    "trainset = dataset_train.iloc[:,1:2].values\n",
    "trainset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0,1))\n",
    "training_scaled = sc.fit_transform(trainset)\n",
    "training_scaled\n",
    "x_train = []\n",
    "y_train = []\n",
    "for i in range(60,1259):\n",
    "    x_train.append(training_scaled[i-60:i, 0])\n",
    "    y_train.append(training_scaled[i,0])\n",
    "x_train,y_train = np.array(x_train),np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DPBKo9bbUJKk",
    "outputId": "2552aab4-ee58-4cf5-eeed-b72d47473436"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1199, 60)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "dataset_train = pd.read_csv('trainset.csv')\n",
    "dataset_train\n",
    "trainset = dataset_train.iloc[:,1:2].values\n",
    "trainset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0,1))\n",
    "training_scaled = sc.fit_transform(trainset)\n",
    "training_scaled\n",
    "x_train = []\n",
    "y_train = []\n",
    "for i in range(60,1259):\n",
    "    x_train.append(training_scaled[i-60:i, 0])\n",
    "    y_train.append(training_scaled[i,0])\n",
    "x_train,y_train = np.array(x_train),np.array(y_train)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aXGufDpXUNSJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "dataset_train = pd.read_csv('trainset.csv')\n",
    "dataset_train\n",
    "trainset = dataset_train.iloc[:,1:2].values\n",
    "trainset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0,1))\n",
    "training_scaled = sc.fit_transform(trainset)\n",
    "training_scaled\n",
    "x_train = []\n",
    "y_train = []\n",
    "for i in range(60,1259):\n",
    "    x_train.append(training_scaled[i-60:i, 0])\n",
    "    y_train.append(training_scaled[i,0])\n",
    "x_train,y_train = np.array(x_train),np.array(y_train)\n",
    "x_train.shape\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1199, 60, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "dataset_train = pd.read_csv('trainset.csv')\n",
    "dataset_train\n",
    "trainset = dataset_train.iloc[:,1:2].values\n",
    "trainset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0,1))\n",
    "training_scaled = sc.fit_transform(trainset)\n",
    "training_scaled\n",
    "x_train = []\n",
    "y_train = []\n",
    "for i in range(60,1259):\n",
    "    x_train.append(training_scaled[i-60:i, 0])\n",
    "    y_train.append(training_scaled[i,0])\n",
    "x_train,y_train = np.array(x_train),np.array(y_train)\n",
    "x_train.shape\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XHYiuuwOUR7c"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "dataset_train = pd.read_csv('trainset.csv')\n",
    "dataset_train\n",
    "trainset = dataset_train.iloc[:,1:2].values\n",
    "trainset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0,1))\n",
    "training_scaled = sc.fit_transform(trainset)\n",
    "training_scaled\n",
    "x_train = []\n",
    "y_train = []\n",
    "for i in range(60,1259):\n",
    "    x_train.append(training_scaled[i-60:i, 0])\n",
    "    y_train.append(training_scaled[i,0])\n",
    "x_train,y_train = np.array(x_train),np.array(y_train)\n",
    "x_train.shape\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
    "x_train.shape\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LUCQkeaDUcTY",
    "outputId": "135b4708-4df9-4a15-e124-ef31bc6a32e2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\new_compant\\Training\\test\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "dataset_train = pd.read_csv('trainset.csv')\n",
    "dataset_train\n",
    "trainset = dataset_train.iloc[:,1:2].values\n",
    "trainset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0,1))\n",
    "training_scaled = sc.fit_transform(trainset)\n",
    "training_scaled\n",
    "x_train = []\n",
    "y_train = []\n",
    "for i in range(60,1259):\n",
    "    x_train.append(training_scaled[i-60:i, 0])\n",
    "    y_train.append(training_scaled[i,0])\n",
    "x_train,y_train = np.array(x_train),np.array(y_train)\n",
    "x_train.shape\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
    "x_train.shape\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Dropout\n",
    "regressor = Sequential()\n",
    "regressor.add(SimpleRNN(units = 50,return_sequences = True,input_shape = (x_train.shape[1],1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hXMU0C8GUb7C"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "dataset_train = pd.read_csv('trainset.csv')\n",
    "dataset_train\n",
    "trainset = dataset_train.iloc[:,1:2].values\n",
    "trainset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0,1))\n",
    "training_scaled = sc.fit_transform(trainset)\n",
    "training_scaled\n",
    "x_train = []\n",
    "y_train = []\n",
    "for i in range(60,1259):\n",
    "    x_train.append(training_scaled[i-60:i, 0])\n",
    "    y_train.append(training_scaled[i,0])\n",
    "x_train,y_train = np.array(x_train),np.array(y_train)\n",
    "x_train.shape\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
    "x_train.shape\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Dropout\n",
    "regressor = Sequential()\n",
    "regressor.add(SimpleRNN(units = 50,return_sequences = True,input_shape = (x_train.shape[1],1)))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wpc6xrBWUbyx"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "dataset_train = pd.read_csv('trainset.csv')\n",
    "dataset_train\n",
    "trainset = dataset_train.iloc[:,1:2].values\n",
    "trainset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0,1))\n",
    "training_scaled = sc.fit_transform(trainset)\n",
    "training_scaled\n",
    "x_train = []\n",
    "y_train = []\n",
    "for i in range(60,1259):\n",
    "    x_train.append(training_scaled[i-60:i, 0])\n",
    "    y_train.append(training_scaled[i,0])\n",
    "x_train,y_train = np.array(x_train),np.array(y_train)\n",
    "x_train.shape\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
    "x_train.shape\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Dropout\n",
    "regressor = Sequential()\n",
    "regressor.add(SimpleRNN(units = 50,return_sequences = True,input_shape = (x_train.shape[1],1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(SimpleRNN(units = 50,return_sequences = True))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AW-Io-ChUbum"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "dataset_train = pd.read_csv('trainset.csv')\n",
    "dataset_train\n",
    "trainset = dataset_train.iloc[:,1:2].values\n",
    "trainset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0,1))\n",
    "training_scaled = sc.fit_transform(trainset)\n",
    "training_scaled\n",
    "x_train = []\n",
    "y_train = []\n",
    "for i in range(60,1259):\n",
    "    x_train.append(training_scaled[i-60:i, 0])\n",
    "    y_train.append(training_scaled[i,0])\n",
    "x_train,y_train = np.array(x_train),np.array(y_train)\n",
    "x_train.shape\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
    "x_train.shape\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Dropout\n",
    "regressor = Sequential()\n",
    "regressor.add(SimpleRNN(units = 50,return_sequences = True,input_shape = (x_train.shape[1],1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(SimpleRNN(units = 50,return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(SimpleRNN(units = 50))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TeZi8_ViUbqd"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "dataset_train = pd.read_csv('trainset.csv')\n",
    "dataset_train\n",
    "trainset = dataset_train.iloc[:,1:2].values\n",
    "trainset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0,1))\n",
    "training_scaled = sc.fit_transform(trainset)\n",
    "training_scaled\n",
    "x_train = []\n",
    "y_train = []\n",
    "for i in range(60,1259):\n",
    "    x_train.append(training_scaled[i-60:i, 0])\n",
    "    y_train.append(training_scaled[i,0])\n",
    "x_train,y_train = np.array(x_train),np.array(y_train)\n",
    "x_train.shape\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
    "x_train.shape\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Dropout\n",
    "regressor = Sequential()\n",
    "regressor.add(SimpleRNN(units = 50,return_sequences = True,input_shape = (x_train.shape[1],1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(SimpleRNN(units = 50,return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(SimpleRNN(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(Dense(units = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,600</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,050</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,050</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m50\u001b[0m)              │           \u001b[38;5;34m2,600\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m50\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn_1 (\u001b[38;5;33mSimpleRNN\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m50\u001b[0m)              │           \u001b[38;5;34m5,050\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m50\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn_2 (\u001b[38;5;33mSimpleRNN\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │           \u001b[38;5;34m5,050\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m51\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,255</span> (149.44 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m38,255\u001b[0m (149.44 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,751</span> (49.81 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,751\u001b[0m (49.81 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,504</span> (99.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m25,504\u001b[0m (99.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "dataset_train = pd.read_csv('trainset.csv')\n",
    "dataset_train\n",
    "trainset = dataset_train.iloc[:,1:2].values\n",
    "trainset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0,1))\n",
    "training_scaled = sc.fit_transform(trainset)\n",
    "training_scaled\n",
    "x_train = []\n",
    "y_train = []\n",
    "for i in range(60,1259):\n",
    "    x_train.append(training_scaled[i-60:i, 0])\n",
    "    y_train.append(training_scaled[i,0])\n",
    "x_train,y_train = np.array(x_train),np.array(y_train)\n",
    "x_train.shape\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
    "x_train.shape\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Dropout\n",
    "regressor = Sequential()\n",
    "regressor.add(SimpleRNN(units = 50,return_sequences = True,input_shape = (x_train.shape[1],1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(SimpleRNN(units = 50,return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(SimpleRNN(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(Dense(units = 1))\n",
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QpCmfsHXUbgJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "dataset_train = pd.read_csv('trainset.csv')\n",
    "dataset_train\n",
    "trainset = dataset_train.iloc[:,1:2].values\n",
    "trainset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0,1))\n",
    "training_scaled = sc.fit_transform(trainset)\n",
    "training_scaled\n",
    "x_train = []\n",
    "y_train = []\n",
    "for i in range(60,1259):\n",
    "    x_train.append(training_scaled[i-60:i, 0])\n",
    "    y_train.append(training_scaled[i,0])\n",
    "x_train,y_train = np.array(x_train),np.array(y_train)\n",
    "x_train.shape\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
    "x_train.shape\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Dropout\n",
    "regressor = Sequential()\n",
    "regressor.add(SimpleRNN(units = 50,return_sequences = True,input_shape = (x_train.shape[1],1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(SimpleRNN(units = 50,return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(SimpleRNN(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(Dense(units = 1))\n",
    "regressor.summary()\n",
    "regressor.compile(optimizer = 'adam',loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "266Dn77lU1c0",
    "outputId": "c05c894d-183b-48b7-c774-b067aa69868c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 0.3619\n",
      "Epoch 2/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.1426\n",
      "Epoch 3/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0838\n",
      "Epoch 4/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.0581\n",
      "Epoch 5/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0509\n",
      "Epoch 6/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0375\n",
      "Epoch 7/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0303\n",
      "Epoch 8/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0275\n",
      "Epoch 9/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0235\n",
      "Epoch 10/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0186\n",
      "Epoch 11/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.0161\n",
      "Epoch 12/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0153\n",
      "Epoch 13/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0140\n",
      "Epoch 14/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0132\n",
      "Epoch 15/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0110\n",
      "Epoch 16/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.0100\n",
      "Epoch 17/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.0100\n",
      "Epoch 18/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.0099\n",
      "Epoch 19/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0083\n",
      "Epoch 20/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0077\n",
      "Epoch 21/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0071\n",
      "Epoch 22/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0071\n",
      "Epoch 23/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0062\n",
      "Epoch 24/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.0072\n",
      "Epoch 25/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 0.0063\n",
      "Epoch 26/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.0059\n",
      "Epoch 27/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.0054\n",
      "Epoch 28/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.0052\n",
      "Epoch 29/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0052\n",
      "Epoch 30/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0044\n",
      "Epoch 31/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0048\n",
      "Epoch 32/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0045\n",
      "Epoch 33/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0045\n",
      "Epoch 34/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0040\n",
      "Epoch 35/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0041\n",
      "Epoch 36/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0038\n",
      "Epoch 37/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.0039\n",
      "Epoch 38/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0038\n",
      "Epoch 39/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.0037\n",
      "Epoch 40/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0035\n",
      "Epoch 41/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.0035\n",
      "Epoch 42/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0034\n",
      "Epoch 43/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0032\n",
      "Epoch 44/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0034\n",
      "Epoch 45/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.0032\n",
      "Epoch 46/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0031\n",
      "Epoch 47/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0030\n",
      "Epoch 48/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0028\n",
      "Epoch 49/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0028\n",
      "Epoch 50/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0027\n",
      "Epoch 51/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0026\n",
      "Epoch 52/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.0025\n",
      "Epoch 53/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0023\n",
      "Epoch 54/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0023\n",
      "Epoch 55/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0025\n",
      "Epoch 56/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.0024\n",
      "Epoch 57/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0023\n",
      "Epoch 58/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0023\n",
      "Epoch 59/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0024\n",
      "Epoch 60/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0023\n",
      "Epoch 61/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - loss: 0.0022\n",
      "Epoch 62/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0020\n",
      "Epoch 63/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.0021\n",
      "Epoch 64/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.0021\n",
      "Epoch 65/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0022\n",
      "Epoch 66/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0021\n",
      "Epoch 67/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.0020\n",
      "Epoch 68/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.0020\n",
      "Epoch 69/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - loss: 0.0021\n",
      "Epoch 70/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0019\n",
      "Epoch 71/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.0017\n",
      "Epoch 72/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.0019\n",
      "Epoch 73/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0017\n",
      "Epoch 74/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0018\n",
      "Epoch 75/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0018\n",
      "Epoch 76/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.0017\n",
      "Epoch 77/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.0015\n",
      "Epoch 78/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0016\n",
      "Epoch 79/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0015\n",
      "Epoch 80/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - loss: 0.0017\n",
      "Epoch 81/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.0018\n",
      "Epoch 82/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.0016\n",
      "Epoch 83/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.0016\n",
      "Epoch 84/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0016\n",
      "Epoch 85/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.0016\n",
      "Epoch 86/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.0017\n",
      "Epoch 87/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0016\n",
      "Epoch 88/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0015\n",
      "Epoch 89/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0017\n",
      "Epoch 90/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0014\n",
      "Epoch 91/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0015\n",
      "Epoch 92/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0013\n",
      "Epoch 93/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0015\n",
      "Epoch 94/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0013\n",
      "Epoch 95/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0015\n",
      "Epoch 96/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.0013\n",
      "Epoch 97/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.0013\n",
      "Epoch 98/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0014\n",
      "Epoch 99/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0013\n",
      "Epoch 100/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0013\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x268bec93460>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "dataset_train = pd.read_csv('trainset.csv')\n",
    "dataset_train\n",
    "trainset = dataset_train.iloc[:,1:2].values\n",
    "trainset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0,1))\n",
    "training_scaled = sc.fit_transform(trainset)\n",
    "training_scaled\n",
    "x_train = []\n",
    "y_train = []\n",
    "for i in range(60,1259):\n",
    "    x_train.append(training_scaled[i-60:i, 0])\n",
    "    y_train.append(training_scaled[i,0])\n",
    "x_train,y_train = np.array(x_train),np.array(y_train)\n",
    "x_train.shape\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
    "x_train.shape\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Dropout\n",
    "regressor = Sequential()\n",
    "regressor.add(SimpleRNN(units = 50,return_sequences = True,input_shape = (x_train.shape[1],1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(SimpleRNN(units = 50,return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(SimpleRNN(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(Dense(units = 1))\n",
    "regressor.summary()\n",
    "regressor.compile(optimizer = 'adam',loss = 'mean_squared_error')\n",
    "regressor.fit(x_train,y_train,epochs = 100, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8CSzMQocW9-M"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "dataset_train = pd.read_csv('trainset.csv')\n",
    "dataset_train\n",
    "trainset = dataset_train.iloc[:,1:2].values\n",
    "trainset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0,1))\n",
    "training_scaled = sc.fit_transform(trainset)\n",
    "training_scaled\n",
    "x_train = []\n",
    "y_train = []\n",
    "for i in range(60,1259):\n",
    "    x_train.append(training_scaled[i-60:i, 0])\n",
    "    y_train.append(training_scaled[i,0])\n",
    "x_train,y_train = np.array(x_train),np.array(y_train)\n",
    "x_train.shape\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
    "x_train.shape\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Dropout\n",
    "regressor = Sequential()\n",
    "regressor.add(SimpleRNN(units = 50,return_sequences = True,input_shape = (x_train.shape[1],1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(SimpleRNN(units = 50,return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(SimpleRNN(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(Dense(units = 1))\n",
    "regressor.summary()\n",
    "regressor.compile(optimizer = 'adam',loss = 'mean_squared_error')\n",
    "regressor.fit(x_train,y_train,epochs = 100, batch_size = 32)\n",
    "dataset_test =pd.read_csv(\"testset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4o0JJIJmXDHl"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "dataset_train = pd.read_csv('trainset.csv')\n",
    "dataset_train\n",
    "trainset = dataset_train.iloc[:,1:2].values\n",
    "trainset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0,1))\n",
    "training_scaled = sc.fit_transform(trainset)\n",
    "training_scaled\n",
    "x_train = []\n",
    "y_train = []\n",
    "for i in range(60,1259):\n",
    "    x_train.append(training_scaled[i-60:i, 0])\n",
    "    y_train.append(training_scaled[i,0])\n",
    "x_train,y_train = np.array(x_train),np.array(y_train)\n",
    "x_train.shape\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
    "x_train.shape\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Dropout\n",
    "regressor = Sequential()\n",
    "regressor.add(SimpleRNN(units = 50,return_sequences = True,input_shape = (x_train.shape[1],1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(SimpleRNN(units = 50,return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(SimpleRNN(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(Dense(units = 1))\n",
    "regressor.summary()\n",
    "regressor.compile(optimizer = 'adam',loss = 'mean_squared_error')\n",
    "regressor.fit(x_train,y_train,epochs = 100, batch_size = 32)\n",
    "dataset_test =pd.read_csv(\"testset.csv\")\n",
    "real_stock_price = dataset_test.iloc[:,1:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1048.339966],\n",
       "       [1064.310059],\n",
       "       [1088.      ],\n",
       "       [1094.      ],\n",
       "       [1102.22998 ],\n",
       "       [1109.400024],\n",
       "       [1097.099976],\n",
       "       [1106.300049],\n",
       "       [1102.410034],\n",
       "       [1132.51001 ],\n",
       "       [1126.219971],\n",
       "       [1131.410034],\n",
       "       [1131.829956],\n",
       "       [1137.48999 ],\n",
       "       [1159.849976],\n",
       "       [1177.329956],\n",
       "       [1172.530029],\n",
       "       [1175.079956],\n",
       "       [1176.47998 ],\n",
       "       [1167.829956],\n",
       "       [1170.569946],\n",
       "       [1162.609985],\n",
       "       [1122.      ],\n",
       "       [1090.599976],\n",
       "       [1027.180054],\n",
       "       [1081.540039],\n",
       "       [1055.410034],\n",
       "       [1017.25    ],\n",
       "       [1048.      ],\n",
       "       [1045.      ],\n",
       "       [1048.949951],\n",
       "       [1079.069946],\n",
       "       [1088.410034],\n",
       "       [1090.569946],\n",
       "       [1106.469971],\n",
       "       [1116.189941],\n",
       "       [1112.640015],\n",
       "       [1127.800049],\n",
       "       [1141.23999 ],\n",
       "       [1123.030029],\n",
       "       [1107.869995],\n",
       "       [1053.079956],\n",
       "       [1075.140015],\n",
       "       [1099.219971],\n",
       "       [1089.189941],\n",
       "       [1115.319946],\n",
       "       [1136.      ],\n",
       "       [1163.849976],\n",
       "       [1170.      ],\n",
       "       [1145.209961],\n",
       "       [1149.959961],\n",
       "       [1154.140015],\n",
       "       [1120.01001 ],\n",
       "       [1099.      ],\n",
       "       [1092.73999 ],\n",
       "       [1081.880005],\n",
       "       [1047.030029],\n",
       "       [1046.      ],\n",
       "       [1063.      ],\n",
       "       [ 998.      ],\n",
       "       [1011.630005],\n",
       "       [1022.820007],\n",
       "       [1013.909973],\n",
       "       [ 993.409973],\n",
       "       [1041.329956],\n",
       "       [1020.      ],\n",
       "       [1016.799988],\n",
       "       [1026.439941],\n",
       "       [1027.98999 ],\n",
       "       [1025.040039],\n",
       "       [1040.880005],\n",
       "       [1037.      ],\n",
       "       [1051.369995],\n",
       "       [1077.430054],\n",
       "       [1069.400024],\n",
       "       [1082.      ],\n",
       "       [1077.859985],\n",
       "       [1052.      ],\n",
       "       [1025.52002 ],\n",
       "       [1029.51001 ],\n",
       "       [1046.      ],\n",
       "       [1030.01001 ],\n",
       "       [1013.659973],\n",
       "       [1028.099976],\n",
       "       [1019.      ],\n",
       "       [1016.900024],\n",
       "       [1049.22998 ],\n",
       "       [1058.540039],\n",
       "       [1058.099976],\n",
       "       [1086.030029],\n",
       "       [1093.599976],\n",
       "       [1100.      ],\n",
       "       [1090.      ],\n",
       "       [1077.310059],\n",
       "       [1079.890015],\n",
       "       [1061.859985],\n",
       "       [1074.060059],\n",
       "       [1083.560059],\n",
       "       [1065.130005],\n",
       "       [1079.      ],\n",
       "       [1079.02002 ],\n",
       "       [1064.890015],\n",
       "       [1063.030029],\n",
       "       [1067.560059],\n",
       "       [1099.349976],\n",
       "       [1122.329956],\n",
       "       [1140.98999 ],\n",
       "       [1142.170044],\n",
       "       [1131.319946],\n",
       "       [1118.180054],\n",
       "       [1118.599976],\n",
       "       [1131.069946],\n",
       "       [1141.119995],\n",
       "       [1143.849976],\n",
       "       [1148.859985],\n",
       "       [1143.650024],\n",
       "       [1158.5     ],\n",
       "       [1175.310059],\n",
       "       [1174.849976],\n",
       "       [1159.140015],\n",
       "       [1143.599976],\n",
       "       [1128.      ],\n",
       "       [1121.339966],\n",
       "       [1102.089966],\n",
       "       [1120.      ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "dataset_train = pd.read_csv('trainset.csv')\n",
    "dataset_train\n",
    "trainset = dataset_train.iloc[:,1:2].values\n",
    "trainset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0,1))\n",
    "training_scaled = sc.fit_transform(trainset)\n",
    "training_scaled\n",
    "x_train = []\n",
    "y_train = []\n",
    "for i in range(60,1259):\n",
    "    x_train.append(training_scaled[i-60:i, 0])\n",
    "    y_train.append(training_scaled[i,0])\n",
    "x_train,y_train = np.array(x_train),np.array(y_train)\n",
    "x_train.shape\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
    "x_train.shape\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Dropout\n",
    "regressor = Sequential()\n",
    "regressor.add(SimpleRNN(units = 50,return_sequences = True,input_shape = (x_train.shape[1],1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(SimpleRNN(units = 50,return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(SimpleRNN(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(Dense(units = 1))\n",
    "regressor.summary()\n",
    "regressor.compile(optimizer = 'adam',loss = 'mean_squared_error')\n",
    "regressor.fit(x_train,y_train,epochs = 100, batch_size = 32)\n",
    "dataset_test =pd.read_csv(\"testset.csv\")\n",
    "real_stock_price = dataset_test.iloc[:,1:2].values\n",
    "real_stock_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "QpkBDy9RXFiH",
    "outputId": "8f6192e2-3358-4ba4-d771-a29a44eb0dce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       357.385559\n",
       "1       360.122742\n",
       "2       362.313507\n",
       "3       365.348755\n",
       "4       365.393463\n",
       "          ...     \n",
       "120    1143.599976\n",
       "121    1128.000000\n",
       "122    1121.339966\n",
       "123    1102.089966\n",
       "124    1120.000000\n",
       "Name: Open, Length: 1384, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "dataset_train = pd.read_csv('trainset.csv')\n",
    "dataset_train\n",
    "trainset = dataset_train.iloc[:,1:2].values\n",
    "trainset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0,1))\n",
    "training_scaled = sc.fit_transform(trainset)\n",
    "training_scaled\n",
    "x_train = []\n",
    "y_train = []\n",
    "for i in range(60,1259):\n",
    "    x_train.append(training_scaled[i-60:i, 0])\n",
    "    y_train.append(training_scaled[i,0])\n",
    "x_train,y_train = np.array(x_train),np.array(y_train)\n",
    "x_train.shape\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
    "x_train.shape\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Dropout\n",
    "regressor = Sequential()\n",
    "regressor.add(SimpleRNN(units = 50,return_sequences = True,input_shape = (x_train.shape[1],1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(SimpleRNN(units = 50,return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(SimpleRNN(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(Dense(units = 1))\n",
    "regressor.summary()\n",
    "regressor.compile(optimizer = 'adam',loss = 'mean_squared_error')\n",
    "regressor.fit(x_train,y_train,epochs = 100, batch_size = 32)\n",
    "dataset_test =pd.read_csv(\"testset.csv\")\n",
    "real_stock_price = dataset_test.iloc[:,1:2].values\n",
    "real_stock_price\n",
    "dataset_total = pd.concat((dataset_train['Open'],dataset_test['Open']),axis = 0)\n",
    "dataset_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NMVWpXCXXJZO",
    "outputId": "e920d66c-3670-48b0-b96c-88b3eede1323"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 955.48999 ,  966.700012,  980.      ,  980.      ,  973.719971,\n",
       "        987.450012,  992.      ,  992.099976,  990.289978,  991.77002 ,\n",
       "        986.      ,  989.440002,  989.52002 ,  970.      ,  968.369995,\n",
       "        980.      , 1009.190002, 1014.      , 1015.219971, 1017.210022,\n",
       "       1021.76001 , 1022.109985, 1028.98999 , 1027.27002 , 1030.52002 ,\n",
       "       1033.98999 , 1026.459961, 1023.419983, 1022.590027, 1019.210022,\n",
       "       1022.52002 , 1034.01001 , 1020.26001 , 1023.309998, 1035.      ,\n",
       "       1035.869995, 1040.      , 1055.089966, 1042.680054, 1022.369995,\n",
       "       1015.799988, 1012.659973,  995.940002, 1001.5     , 1020.429993,\n",
       "       1037.48999 , 1035.5     , 1039.630005, 1046.119995, 1045.      ,\n",
       "       1054.609985, 1066.079956, 1075.199951, 1071.780029, 1064.949951,\n",
       "       1061.109985, 1058.069946, 1057.390015, 1051.599976, 1046.719971,\n",
       "       1048.339966, 1064.310059, 1088.      , 1094.      , 1102.22998 ,\n",
       "       1109.400024, 1097.099976, 1106.300049, 1102.410034, 1132.51001 ,\n",
       "       1126.219971, 1131.410034, 1131.829956, 1137.48999 , 1159.849976,\n",
       "       1177.329956, 1172.530029, 1175.079956, 1176.47998 , 1167.829956,\n",
       "       1170.569946, 1162.609985, 1122.      , 1090.599976, 1027.180054,\n",
       "       1081.540039, 1055.410034, 1017.25    , 1048.      , 1045.      ,\n",
       "       1048.949951, 1079.069946, 1088.410034, 1090.569946, 1106.469971,\n",
       "       1116.189941, 1112.640015, 1127.800049, 1141.23999 , 1123.030029,\n",
       "       1107.869995, 1053.079956, 1075.140015, 1099.219971, 1089.189941,\n",
       "       1115.319946, 1136.      , 1163.849976, 1170.      , 1145.209961,\n",
       "       1149.959961, 1154.140015, 1120.01001 , 1099.      , 1092.73999 ,\n",
       "       1081.880005, 1047.030029, 1046.      , 1063.      ,  998.      ,\n",
       "       1011.630005, 1022.820007, 1013.909973,  993.409973, 1041.329956,\n",
       "       1020.      , 1016.799988, 1026.439941, 1027.98999 , 1025.040039,\n",
       "       1040.880005, 1037.      , 1051.369995, 1077.430054, 1069.400024,\n",
       "       1082.      , 1077.859985, 1052.      , 1025.52002 , 1029.51001 ,\n",
       "       1046.      , 1030.01001 , 1013.659973, 1028.099976, 1019.      ,\n",
       "       1016.900024, 1049.22998 , 1058.540039, 1058.099976, 1086.030029,\n",
       "       1093.599976, 1100.      , 1090.      , 1077.310059, 1079.890015,\n",
       "       1061.859985, 1074.060059, 1083.560059, 1065.130005, 1079.      ,\n",
       "       1079.02002 , 1064.890015, 1063.030029, 1067.560059, 1099.349976,\n",
       "       1122.329956, 1140.98999 , 1142.170044, 1131.319946, 1118.180054,\n",
       "       1118.599976, 1131.069946, 1141.119995, 1143.849976, 1148.859985,\n",
       "       1143.650024, 1158.5     , 1175.310059, 1174.849976, 1159.140015,\n",
       "       1143.599976, 1128.      , 1121.339966, 1102.089966, 1120.      ])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "dataset_train = pd.read_csv('trainset.csv')\n",
    "dataset_train\n",
    "trainset = dataset_train.iloc[:,1:2].values\n",
    "trainset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0,1))\n",
    "training_scaled = sc.fit_transform(trainset)\n",
    "training_scaled\n",
    "x_train = []\n",
    "y_train = []\n",
    "for i in range(60,1259):\n",
    "    x_train.append(training_scaled[i-60:i, 0])\n",
    "    y_train.append(training_scaled[i,0])\n",
    "x_train,y_train = np.array(x_train),np.array(y_train)\n",
    "x_train.shape\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
    "x_train.shape\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Dropout\n",
    "regressor = Sequential()\n",
    "regressor.add(SimpleRNN(units = 50,return_sequences = True,input_shape = (x_train.shape[1],1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(SimpleRNN(units = 50,return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(SimpleRNN(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(Dense(units = 1))\n",
    "regressor.summary()\n",
    "regressor.compile(optimizer = 'adam',loss = 'mean_squared_error')\n",
    "regressor.fit(x_train,y_train,epochs = 100, batch_size = 32)\n",
    "dataset_test =pd.read_csv(\"testset.csv\")\n",
    "real_stock_price = dataset_test.iloc[:,1:2].values\n",
    "real_stock_price\n",
    "dataset_total = pd.concat((dataset_train['Open'],dataset_test['Open']),axis = 0)\n",
    "dataset_total\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test)-60:].values\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z6uXGoWCXW0D"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "dataset_train = pd.read_csv('trainset.csv')\n",
    "dataset_train\n",
    "trainset = dataset_train.iloc[:,1:2].values\n",
    "trainset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0,1))\n",
    "training_scaled = sc.fit_transform(trainset)\n",
    "training_scaled\n",
    "x_train = []\n",
    "y_train = []\n",
    "for i in range(60,1259):\n",
    "    x_train.append(training_scaled[i-60:i, 0])\n",
    "    y_train.append(training_scaled[i,0])\n",
    "x_train,y_train = np.array(x_train),np.array(y_train)\n",
    "x_train.shape\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
    "x_train.shape\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Dropout\n",
    "regressor = Sequential()\n",
    "regressor.add(SimpleRNN(units = 50,return_sequences = True,input_shape = (x_train.shape[1],1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(SimpleRNN(units = 50,return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(SimpleRNN(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(Dense(units = 1))\n",
    "regressor.summary()\n",
    "regressor.compile(optimizer = 'adam',loss = 'mean_squared_error')\n",
    "regressor.fit(x_train,y_train,epochs = 100, batch_size = 32)\n",
    "dataset_test =pd.read_csv(\"testset.csv\")\n",
    "real_stock_price = dataset_test.iloc[:,1:2].values\n",
    "real_stock_price\n",
    "dataset_total = pd.concat((dataset_train['Open'],dataset_test['Open']),axis = 0)\n",
    "dataset_total\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test)-60:].values\n",
    "inputs\n",
    "inputs = inputs.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Vz6AVuUXZXx",
    "outputId": "2aa2d339-8d82-400d-cc98-98fa8b9ca7b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 955.48999 ],\n",
       "       [ 966.700012],\n",
       "       [ 980.      ],\n",
       "       [ 980.      ],\n",
       "       [ 973.719971],\n",
       "       [ 987.450012],\n",
       "       [ 992.      ],\n",
       "       [ 992.099976],\n",
       "       [ 990.289978],\n",
       "       [ 991.77002 ],\n",
       "       [ 986.      ],\n",
       "       [ 989.440002],\n",
       "       [ 989.52002 ],\n",
       "       [ 970.      ],\n",
       "       [ 968.369995],\n",
       "       [ 980.      ],\n",
       "       [1009.190002],\n",
       "       [1014.      ],\n",
       "       [1015.219971],\n",
       "       [1017.210022],\n",
       "       [1021.76001 ],\n",
       "       [1022.109985],\n",
       "       [1028.98999 ],\n",
       "       [1027.27002 ],\n",
       "       [1030.52002 ],\n",
       "       [1033.98999 ],\n",
       "       [1026.459961],\n",
       "       [1023.419983],\n",
       "       [1022.590027],\n",
       "       [1019.210022],\n",
       "       [1022.52002 ],\n",
       "       [1034.01001 ],\n",
       "       [1020.26001 ],\n",
       "       [1023.309998],\n",
       "       [1035.      ],\n",
       "       [1035.869995],\n",
       "       [1040.      ],\n",
       "       [1055.089966],\n",
       "       [1042.680054],\n",
       "       [1022.369995],\n",
       "       [1015.799988],\n",
       "       [1012.659973],\n",
       "       [ 995.940002],\n",
       "       [1001.5     ],\n",
       "       [1020.429993],\n",
       "       [1037.48999 ],\n",
       "       [1035.5     ],\n",
       "       [1039.630005],\n",
       "       [1046.119995],\n",
       "       [1045.      ],\n",
       "       [1054.609985],\n",
       "       [1066.079956],\n",
       "       [1075.199951],\n",
       "       [1071.780029],\n",
       "       [1064.949951],\n",
       "       [1061.109985],\n",
       "       [1058.069946],\n",
       "       [1057.390015],\n",
       "       [1051.599976],\n",
       "       [1046.719971],\n",
       "       [1048.339966],\n",
       "       [1064.310059],\n",
       "       [1088.      ],\n",
       "       [1094.      ],\n",
       "       [1102.22998 ],\n",
       "       [1109.400024],\n",
       "       [1097.099976],\n",
       "       [1106.300049],\n",
       "       [1102.410034],\n",
       "       [1132.51001 ],\n",
       "       [1126.219971],\n",
       "       [1131.410034],\n",
       "       [1131.829956],\n",
       "       [1137.48999 ],\n",
       "       [1159.849976],\n",
       "       [1177.329956],\n",
       "       [1172.530029],\n",
       "       [1175.079956],\n",
       "       [1176.47998 ],\n",
       "       [1167.829956],\n",
       "       [1170.569946],\n",
       "       [1162.609985],\n",
       "       [1122.      ],\n",
       "       [1090.599976],\n",
       "       [1027.180054],\n",
       "       [1081.540039],\n",
       "       [1055.410034],\n",
       "       [1017.25    ],\n",
       "       [1048.      ],\n",
       "       [1045.      ],\n",
       "       [1048.949951],\n",
       "       [1079.069946],\n",
       "       [1088.410034],\n",
       "       [1090.569946],\n",
       "       [1106.469971],\n",
       "       [1116.189941],\n",
       "       [1112.640015],\n",
       "       [1127.800049],\n",
       "       [1141.23999 ],\n",
       "       [1123.030029],\n",
       "       [1107.869995],\n",
       "       [1053.079956],\n",
       "       [1075.140015],\n",
       "       [1099.219971],\n",
       "       [1089.189941],\n",
       "       [1115.319946],\n",
       "       [1136.      ],\n",
       "       [1163.849976],\n",
       "       [1170.      ],\n",
       "       [1145.209961],\n",
       "       [1149.959961],\n",
       "       [1154.140015],\n",
       "       [1120.01001 ],\n",
       "       [1099.      ],\n",
       "       [1092.73999 ],\n",
       "       [1081.880005],\n",
       "       [1047.030029],\n",
       "       [1046.      ],\n",
       "       [1063.      ],\n",
       "       [ 998.      ],\n",
       "       [1011.630005],\n",
       "       [1022.820007],\n",
       "       [1013.909973],\n",
       "       [ 993.409973],\n",
       "       [1041.329956],\n",
       "       [1020.      ],\n",
       "       [1016.799988],\n",
       "       [1026.439941],\n",
       "       [1027.98999 ],\n",
       "       [1025.040039],\n",
       "       [1040.880005],\n",
       "       [1037.      ],\n",
       "       [1051.369995],\n",
       "       [1077.430054],\n",
       "       [1069.400024],\n",
       "       [1082.      ],\n",
       "       [1077.859985],\n",
       "       [1052.      ],\n",
       "       [1025.52002 ],\n",
       "       [1029.51001 ],\n",
       "       [1046.      ],\n",
       "       [1030.01001 ],\n",
       "       [1013.659973],\n",
       "       [1028.099976],\n",
       "       [1019.      ],\n",
       "       [1016.900024],\n",
       "       [1049.22998 ],\n",
       "       [1058.540039],\n",
       "       [1058.099976],\n",
       "       [1086.030029],\n",
       "       [1093.599976],\n",
       "       [1100.      ],\n",
       "       [1090.      ],\n",
       "       [1077.310059],\n",
       "       [1079.890015],\n",
       "       [1061.859985],\n",
       "       [1074.060059],\n",
       "       [1083.560059],\n",
       "       [1065.130005],\n",
       "       [1079.      ],\n",
       "       [1079.02002 ],\n",
       "       [1064.890015],\n",
       "       [1063.030029],\n",
       "       [1067.560059],\n",
       "       [1099.349976],\n",
       "       [1122.329956],\n",
       "       [1140.98999 ],\n",
       "       [1142.170044],\n",
       "       [1131.319946],\n",
       "       [1118.180054],\n",
       "       [1118.599976],\n",
       "       [1131.069946],\n",
       "       [1141.119995],\n",
       "       [1143.849976],\n",
       "       [1148.859985],\n",
       "       [1143.650024],\n",
       "       [1158.5     ],\n",
       "       [1175.310059],\n",
       "       [1174.849976],\n",
       "       [1159.140015],\n",
       "       [1143.599976],\n",
       "       [1128.      ],\n",
       "       [1121.339966],\n",
       "       [1102.089966],\n",
       "       [1120.      ]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "dataset_train = pd.read_csv('trainset.csv')\n",
    "dataset_train\n",
    "trainset = dataset_train.iloc[:,1:2].values\n",
    "trainset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0,1))\n",
    "training_scaled = sc.fit_transform(trainset)\n",
    "training_scaled\n",
    "x_train = []\n",
    "y_train = []\n",
    "for i in range(60,1259):\n",
    "    x_train.append(training_scaled[i-60:i, 0])\n",
    "    y_train.append(training_scaled[i,0])\n",
    "x_train,y_train = np.array(x_train),np.array(y_train)\n",
    "x_train.shape\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
    "x_train.shape\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Dropout\n",
    "regressor = Sequential()\n",
    "regressor.add(SimpleRNN(units = 50,return_sequences = True,input_shape = (x_train.shape[1],1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(SimpleRNN(units = 50,return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(SimpleRNN(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(Dense(units = 1))\n",
    "regressor.summary()\n",
    "regressor.compile(optimizer = 'adam',loss = 'mean_squared_error')\n",
    "regressor.fit(x_train,y_train,epochs = 100, batch_size = 32)\n",
    "dataset_test =pd.read_csv(\"testset.csv\")\n",
    "real_stock_price = dataset_test.iloc[:,1:2].values\n",
    "real_stock_price\n",
    "dataset_total = pd.concat((dataset_train['Open'],dataset_test['Open']),axis = 0)\n",
    "dataset_total\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test)-60:].values\n",
    "inputs\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9COmQlH3Xdsz",
    "outputId": "60128a19-5b37-44eb-eb93-3b807328c3dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185, 1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "dataset_train = pd.read_csv('trainset.csv')\n",
    "dataset_train\n",
    "trainset = dataset_train.iloc[:,1:2].values\n",
    "trainset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0,1))\n",
    "training_scaled = sc.fit_transform(trainset)\n",
    "training_scaled\n",
    "x_train = []\n",
    "y_train = []\n",
    "for i in range(60,1259):\n",
    "    x_train.append(training_scaled[i-60:i, 0])\n",
    "    y_train.append(training_scaled[i,0])\n",
    "x_train,y_train = np.array(x_train),np.array(y_train)\n",
    "x_train.shape\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
    "x_train.shape\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Dropout\n",
    "regressor = Sequential()\n",
    "regressor.add(SimpleRNN(units = 50,return_sequences = True,input_shape = (x_train.shape[1],1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(SimpleRNN(units = 50,return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(SimpleRNN(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(Dense(units = 1))\n",
    "regressor.summary()\n",
    "regressor.compile(optimizer = 'adam',loss = 'mean_squared_error')\n",
    "regressor.fit(x_train,y_train,epochs = 100, batch_size = 32)\n",
    "dataset_test =pd.read_csv(\"testset.csv\")\n",
    "real_stock_price = dataset_test.iloc[:,1:2].values\n",
    "real_stock_price\n",
    "dataset_total = pd.concat((dataset_train['Open'],dataset_test['Open']),axis = 0)\n",
    "dataset_total\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test)-60:].values\n",
    "inputs\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs\n",
    "inputs = sc.transform(inputs)\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5JxDbLi7XgdC"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "dataset_train = pd.read_csv('trainset.csv')\n",
    "dataset_train\n",
    "trainset = dataset_train.iloc[:,1:2].values\n",
    "trainset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0,1))\n",
    "training_scaled = sc.fit_transform(trainset)\n",
    "training_scaled\n",
    "x_train = []\n",
    "y_train = []\n",
    "for i in range(60,1259):\n",
    "    x_train.append(training_scaled[i-60:i, 0])\n",
    "    y_train.append(training_scaled[i,0])\n",
    "x_train,y_train = np.array(x_train),np.array(y_train)\n",
    "x_train.shape\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
    "x_train.shape\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Dropout\n",
    "regressor = Sequential()\n",
    "regressor.add(SimpleRNN(units = 50,return_sequences = True,input_shape = (x_train.shape[1],1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(SimpleRNN(units = 50,return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(SimpleRNN(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(Dense(units = 1))\n",
    "regressor.summary()\n",
    "regressor.compile(optimizer = 'adam',loss = 'mean_squared_error')\n",
    "regressor.fit(x_train,y_train,epochs = 100, batch_size = 32)\n",
    "dataset_test =pd.read_csv(\"testset.csv\")\n",
    "real_stock_price = dataset_test.iloc[:,1:2].values\n",
    "real_stock_price\n",
    "dataset_total = pd.concat((dataset_train['Open'],dataset_test['Open']),axis = 0)\n",
    "dataset_total\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test)-60:].values\n",
    "inputs\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs\n",
    "inputs = sc.transform(inputs)\n",
    "inputs.shape\n",
    "x_test = []\n",
    "for i in range(60,185):\n",
    "    x_test.append(inputs[i-60:i,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-jDHiGxdXhmW",
    "outputId": "4f5fcf3d-5f9e-417d-fdba-e64a77897d0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, 60)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "dataset_train = pd.read_csv('trainset.csv')\n",
    "dataset_train\n",
    "trainset = dataset_train.iloc[:,1:2].values\n",
    "trainset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0,1))\n",
    "training_scaled = sc.fit_transform(trainset)\n",
    "training_scaled\n",
    "x_train = []\n",
    "y_train = []\n",
    "for i in range(60,1259):\n",
    "    x_train.append(training_scaled[i-60:i, 0])\n",
    "    y_train.append(training_scaled[i,0])\n",
    "x_train,y_train = np.array(x_train),np.array(y_train)\n",
    "x_train.shape\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
    "x_train.shape\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Dropout\n",
    "regressor = Sequential()\n",
    "regressor.add(SimpleRNN(units = 50,return_sequences = True,input_shape = (x_train.shape[1],1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(SimpleRNN(units = 50,return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(SimpleRNN(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(Dense(units = 1))\n",
    "regressor.summary()\n",
    "regressor.compile(optimizer = 'adam',loss = 'mean_squared_error')\n",
    "regressor.fit(x_train,y_train,epochs = 100, batch_size = 32)\n",
    "dataset_test =pd.read_csv(\"testset.csv\")\n",
    "real_stock_price = dataset_test.iloc[:,1:2].values\n",
    "real_stock_price\n",
    "dataset_total = pd.concat((dataset_train['Open'],dataset_test['Open']),axis = 0)\n",
    "dataset_total\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test)-60:].values\n",
    "inputs\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs\n",
    "inputs = sc.transform(inputs)\n",
    "inputs.shape\n",
    "x_test = []\n",
    "for i in range(60,185):\n",
    "    x_test.append(inputs[i-60:i,0])\n",
    "x_test = np.array(x_test)\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xo3YfHYPXkcS",
    "outputId": "a64b2c18-9374-49d8-c7f2-75d3a62f148f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, 60, 1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "dataset_train = pd.read_csv('trainset.csv')\n",
    "dataset_train\n",
    "trainset = dataset_train.iloc[:,1:2].values\n",
    "trainset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0,1))\n",
    "training_scaled = sc.fit_transform(trainset)\n",
    "training_scaled\n",
    "x_train = []\n",
    "y_train = []\n",
    "for i in range(60,1259):\n",
    "    x_train.append(training_scaled[i-60:i, 0])\n",
    "    y_train.append(training_scaled[i,0])\n",
    "x_train,y_train = np.array(x_train),np.array(y_train)\n",
    "x_train.shape\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
    "x_train.shape\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Dropout\n",
    "regressor = Sequential()\n",
    "regressor.add(SimpleRNN(units = 50,return_sequences = True,input_shape = (x_train.shape[1],1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(SimpleRNN(units = 50,return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(SimpleRNN(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(Dense(units = 1))\n",
    "regressor.summary()\n",
    "regressor.compile(optimizer = 'adam',loss = 'mean_squared_error')\n",
    "regressor.fit(x_train,y_train,epochs = 100, batch_size = 32)\n",
    "dataset_test =pd.read_csv(\"testset.csv\")\n",
    "real_stock_price = dataset_test.iloc[:,1:2].values\n",
    "real_stock_price\n",
    "dataset_total = pd.concat((dataset_train['Open'],dataset_test['Open']),axis = 0)\n",
    "dataset_total\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test)-60:].values\n",
    "inputs\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs\n",
    "inputs = sc.transform(inputs)\n",
    "inputs.shape\n",
    "x_test = []\n",
    "for i in range(60,185):\n",
    "    x_test.append(inputs[i-60:i,0])\n",
    "x_test = np.array(x_test)\n",
    "x_test.shape\n",
    "x_test = np.reshape(x_test, (x_test.shape[0],x_test.shape[1],1))\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2OPXSnxIXnou",
    "outputId": "ccb02702-746a-40ea-a05b-b3803a4bc74b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 264ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "dataset_train = pd.read_csv('trainset.csv')\n",
    "dataset_train\n",
    "trainset = dataset_train.iloc[:,1:2].values\n",
    "trainset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0,1))\n",
    "training_scaled = sc.fit_transform(trainset)\n",
    "training_scaled\n",
    "x_train = []\n",
    "y_train = []\n",
    "for i in range(60,1259):\n",
    "    x_train.append(training_scaled[i-60:i, 0])\n",
    "    y_train.append(training_scaled[i,0])\n",
    "x_train,y_train = np.array(x_train),np.array(y_train)\n",
    "x_train.shape\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
    "x_train.shape\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Dropout\n",
    "regressor = Sequential()\n",
    "regressor.add(SimpleRNN(units = 50,return_sequences = True,input_shape = (x_train.shape[1],1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(SimpleRNN(units = 50,return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(SimpleRNN(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(Dense(units = 1))\n",
    "regressor.summary()\n",
    "regressor.compile(optimizer = 'adam',loss = 'mean_squared_error')\n",
    "regressor.fit(x_train,y_train,epochs = 100, batch_size = 32)\n",
    "dataset_test =pd.read_csv(\"testset.csv\")\n",
    "real_stock_price = dataset_test.iloc[:,1:2].values\n",
    "real_stock_price\n",
    "dataset_total = pd.concat((dataset_train['Open'],dataset_test['Open']),axis = 0)\n",
    "dataset_total\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test)-60:].values\n",
    "inputs\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs\n",
    "inputs = sc.transform(inputs)\n",
    "inputs.shape\n",
    "x_test = []\n",
    "for i in range(60,185):\n",
    "    x_test.append(inputs[i-60:i,0])\n",
    "x_test = np.array(x_test)\n",
    "x_test.shape\n",
    "x_test = np.reshape(x_test, (x_test.shape[0],x_test.shape[1],1))\n",
    "x_test.shape\n",
    "predicted_price = regressor.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "blQpUec_XrXL",
    "outputId": "172cc688-3328-46ac-b5c3-af93accc4548"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1022.72266],\n",
       "       [1024.7627 ],\n",
       "       [1033.8834 ],\n",
       "       [1047.7523 ],\n",
       "       [1056.6821 ],\n",
       "       [1063.629  ],\n",
       "       [1069.9591 ],\n",
       "       [1064.6301 ],\n",
       "       [1065.0454 ],\n",
       "       [1067.1058 ],\n",
       "       [1080.6606 ],\n",
       "       [1084.4536 ],\n",
       "       [1089.6711 ],\n",
       "       [1091.8174 ],\n",
       "       [1095.4943 ],\n",
       "       [1107.101  ],\n",
       "       [1121.6561 ],\n",
       "       [1123.0919 ],\n",
       "       [1123.0758 ],\n",
       "       [1127.2358 ],\n",
       "       [1125.1862 ],\n",
       "       [1122.1119 ],\n",
       "       [1118.645  ],\n",
       "       [1098.3309 ],\n",
       "       [1070.05   ],\n",
       "       [1032.6653 ],\n",
       "       [1039.1812 ],\n",
       "       [1040.4657 ],\n",
       "       [1014.4054 ],\n",
       "       [1014.1047 ],\n",
       "       [1027.0327 ],\n",
       "       [1029.0829 ],\n",
       "       [1032.7925 ],\n",
       "       [1047.6068 ],\n",
       "       [1055.6394 ],\n",
       "       [1061.1927 ],\n",
       "       [1071.024  ],\n",
       "       [1074.7026 ],\n",
       "       [1080.9802 ],\n",
       "       [1092.7975 ],\n",
       "       [1089.2625 ],\n",
       "       [1078.2574 ],\n",
       "       [1051.0044 ],\n",
       "       [1044.8118 ],\n",
       "       [1056.2745 ],\n",
       "       [1065.7761 ],\n",
       "       [1071.8322 ],\n",
       "       [1088.6566 ],\n",
       "       [1111.8312 ],\n",
       "       [1118.3076 ],\n",
       "       [1107.4556 ],\n",
       "       [1101.9896 ],\n",
       "       [1104.239  ],\n",
       "       [1091.8363 ],\n",
       "       [1068.3513 ],\n",
       "       [1057.6405 ],\n",
       "       [1060.5945 ],\n",
       "       [1040.193  ],\n",
       "       [1024.0054 ],\n",
       "       [1030.8416 ],\n",
       "       [1008.3877 ],\n",
       "       [ 987.1553 ],\n",
       "       [ 994.7506 ],\n",
       "       [1003.9005 ],\n",
       "       [ 987.71454],\n",
       "       [ 995.8273 ],\n",
       "       [1002.2169 ],\n",
       "       [ 999.9962 ],\n",
       "       [ 994.9079 ],\n",
       "       [1003.71313],\n",
       "       [1004.4692 ],\n",
       "       [1011.6001 ],\n",
       "       [1011.14465],\n",
       "       [1018.7425 ],\n",
       "       [1040.7439 ],\n",
       "       [1049.1611 ],\n",
       "       [1046.7983 ],\n",
       "       [1046.3124 ],\n",
       "       [1040.8907 ],\n",
       "       [1015.5943 ],\n",
       "       [1008.4255 ],\n",
       "       [1016.8536 ],\n",
       "       [1017.32153],\n",
       "       [ 999.202  ],\n",
       "       [1002.836  ],\n",
       "       [1004.887  ],\n",
       "       [1003.7221 ],\n",
       "       [1007.6469 ],\n",
       "       [1021.2205 ],\n",
       "       [1030.0115 ],\n",
       "       [1039.3473 ],\n",
       "       [1049.9313 ],\n",
       "       [1061.0244 ],\n",
       "       [1060.246  ],\n",
       "       [1045.3062 ],\n",
       "       [1044.1232 ],\n",
       "       [1041.4784 ],\n",
       "       [1043.7749 ],\n",
       "       [1045.4878 ],\n",
       "       [1048.5299 ],\n",
       "       [1051.1492 ],\n",
       "       [1052.4525 ],\n",
       "       [1046.3303 ],\n",
       "       [1037.3909 ],\n",
       "       [1037.4911 ],\n",
       "       [1055.4727 ],\n",
       "       [1075.1255 ],\n",
       "       [1090.2196 ],\n",
       "       [1100.6755 ],\n",
       "       [1095.079  ],\n",
       "       [1085.7834 ],\n",
       "       [1083.4839 ],\n",
       "       [1088.025  ],\n",
       "       [1091.0057 ],\n",
       "       [1098.6782 ],\n",
       "       [1105.7894 ],\n",
       "       [1107.5312 ],\n",
       "       [1114.0856 ],\n",
       "       [1123.9491 ],\n",
       "       [1124.536  ],\n",
       "       [1112.4377 ],\n",
       "       [1104.1855 ],\n",
       "       [1096.146  ],\n",
       "       [1087.7361 ],\n",
       "       [1078.3953 ]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "dataset_train = pd.read_csv('trainset.csv')\n",
    "dataset_train\n",
    "trainset = dataset_train.iloc[:,1:2].values\n",
    "trainset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0,1))\n",
    "training_scaled = sc.fit_transform(trainset)\n",
    "training_scaled\n",
    "x_train = []\n",
    "y_train = []\n",
    "for i in range(60,1259):\n",
    "    x_train.append(training_scaled[i-60:i, 0])\n",
    "    y_train.append(training_scaled[i,0])\n",
    "x_train,y_train = np.array(x_train),np.array(y_train)\n",
    "x_train.shape\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
    "x_train.shape\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Dropout\n",
    "regressor = Sequential()\n",
    "regressor.add(SimpleRNN(units = 50,return_sequences = True,input_shape = (x_train.shape[1],1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(SimpleRNN(units = 50,return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(SimpleRNN(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(Dense(units = 1))\n",
    "regressor.summary()\n",
    "regressor.compile(optimizer = 'adam',loss = 'mean_squared_error')\n",
    "regressor.fit(x_train,y_train,epochs = 100, batch_size = 32)\n",
    "dataset_test =pd.read_csv(\"testset.csv\")\n",
    "real_stock_price = dataset_test.iloc[:,1:2].values\n",
    "real_stock_price\n",
    "dataset_total = pd.concat((dataset_train['Open'],dataset_test['Open']),axis = 0)\n",
    "dataset_total\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test)-60:].values\n",
    "inputs\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs\n",
    "inputs = sc.transform(inputs)\n",
    "inputs.shape\n",
    "x_test = []\n",
    "for i in range(60,185):\n",
    "    x_test.append(inputs[i-60:i,0])\n",
    "x_test = np.array(x_test)\n",
    "x_test.shape\n",
    "x_test = np.reshape(x_test, (x_test.shape[0],x_test.shape[1],1))\n",
    "x_test.shape\n",
    "predicted_price = regressor.predict(x_test)\n",
    "predicted_price = sc.inverse_transform(predicted_price)\n",
    "predicted_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "EQBtrEPvXucr",
    "outputId": "cf19164c-6a09-48e0-f74c-8aaf9128eb8d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "dataset_train = pd.read_csv('trainset.csv')\n",
    "dataset_train\n",
    "trainset = dataset_train.iloc[:,1:2].values\n",
    "trainset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0,1))\n",
    "training_scaled = sc.fit_transform(trainset)\n",
    "training_scaled\n",
    "x_train = []\n",
    "y_train = []\n",
    "for i in range(60,1259):\n",
    "    x_train.append(training_scaled[i-60:i, 0])\n",
    "    y_train.append(training_scaled[i,0])\n",
    "x_train,y_train = np.array(x_train),np.array(y_train)\n",
    "x_train.shape\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
    "x_train.shape\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Dropout\n",
    "regressor = Sequential()\n",
    "regressor.add(SimpleRNN(units = 50,return_sequences = True,input_shape = (x_train.shape[1],1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(SimpleRNN(units = 50,return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(SimpleRNN(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(Dense(units = 1))\n",
    "regressor.summary()\n",
    "regressor.compile(optimizer = 'adam',loss = 'mean_squared_error')\n",
    "regressor.fit(x_train,y_train,epochs = 100, batch_size = 32)\n",
    "dataset_test =pd.read_csv(\"testset.csv\")\n",
    "real_stock_price = dataset_test.iloc[:,1:2].values\n",
    "real_stock_price\n",
    "dataset_total = pd.concat((dataset_train['Open'],dataset_test['Open']),axis = 0)\n",
    "dataset_total\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test)-60:].values\n",
    "inputs\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs\n",
    "inputs = sc.transform(inputs)\n",
    "inputs.shape\n",
    "x_test = []\n",
    "for i in range(60,185):\n",
    "    x_test.append(inputs[i-60:i,0])\n",
    "x_test = np.array(x_test)\n",
    "x_test.shape\n",
    "x_test = np.reshape(x_test, (x_test.shape[0],x_test.shape[1],1))\n",
    "x_test.shape\n",
    "predicted_price = regressor.predict(x_test)\n",
    "predicted_price = sc.inverse_transform(predicted_price)\n",
    "predicted_price\n",
    "plt.plot(real_stock_price,color = 'red', label = 'Real Price')\n",
    "plt.plot(predicted_price, color = 'blue', label = 'Predicted Price')\n",
    "plt.title('Google Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Google Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
